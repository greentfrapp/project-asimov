{
  "Algorithmic Bias": "There are three main categories of algorithmic bias. The first and perhaps the most notorious refers to algorithms that only perform well on certain groups, such as facial recognition performing better on white male faces. Another category of bias refers to algorithms that reinforces human bias and create feedback loops, such as in recidivism prediction. Finally, algorithmic bias can also manifest itself via discriminatory access to algorithmic services.",
  "Black Boxes": "The term 'black boxes' typically refers to deep neural networks and other algorithms that are difficult to explain in a human-understandable manner, leading to concerns over transparency and accountability. In addition, the problem of opacity occurs in all parts of the AI system pipeline. Such cases revolve around issues of appropriate disclosure, informed consent, participatory design and capacity for redress.",
  "Privacy Violation": "Privacy violation includes both purposeful and accidental violation. Purposeful violation includes themes of informed consent and appropriate disclosure of purpose. Accidental violation refers to cases such as cybersecurity breaches, adversarial attacks and membership inference attacks, which revolve around robustness of the AI pipeline.",
  "Misinformation": "Misinformation is a more general form of disinformation, which includes the intent to deceive. This includes fabrication of visual and textual media and wilful impersonation, which have the potential to severly compromise human judgement. To a less extent, misinformation also refers to lack of appropriate disclosures from AI practitioners.",
  "Ghost Work": "The term 'ghost work' refers primarily to low-wage workers who perform data labeling. These workers are often hidden from plain sight and are analagous to low-wage workers in manufacturing environments such as sweatshops.",
  "System Failure": "AI systems are often associated with infallibility and objectivity, unlike their human counterparts. The false sense of security could lead to AI practitioners neglecting risk management and graceful degradation measures. Without proper safeguards, small failures could lead to runaway chain reactions, such as in quantitative finance."
}