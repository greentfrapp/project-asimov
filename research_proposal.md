---
layout: general
title: research proposal. \| Project Asimov
permalink: /research_proposal/
---

<h1 id="title">Research Proposal</h1>

## An outline of [Project Asimov](https://greentfrapp.github.io/project-asimov/), including a brief review of existing literature, methodology, potential challenges and timeline.

<img src="https://greentfrapp.github.io/project-asimov/assets/frontispiece.png" style="width: 100%; max-width: 500px; margin: 25px;">

<dt-byline></dt-byline>

#### Contents

- [Research Background](#research-background)
- [Research Angle](#research-angle)
- [Research Design](#research-design)
- [Potential Challenges](#potential-challenges)
- [Timeline](#timeline)
- [tl;dr](#tldr)
- [Appendix - List of possible case studies](#appendix---list-of-possible-case-studies)

---

## Research Background

Several artificial intelligence (AI) ethics guidelines and frameworks have been published recently, amidst concerns over abuse of the technology and neglect of potentially adverse consequences. Examples include the European Commission's *Ethics Guidelines for Trustworthy AI* ([2019](https://ec.europa.eu/digital-single-market/en/news/ethics-guidelines-trustworthy-ai)), the Organisation for Economic Co-operation and Development's (OECD) *Recommendation of the Council on Artificial Intelligence* ([2019](https://legalinstruments.oecd.org/en/instruments/OECD-LEGAL-0449)), Canada's *Algorithmic Impact Assessment questionnaire* ([2019](https://canada-ca.github.io/aia-eia-js/)), USA's *Algorithmic Accountability Act of 2019* ([2019](https://www.wyden.senate.gov/imo/media/doc/Algorithmic%20Accountability%20Act%20of%202019%20Bill%20Text.pdf)) and Singapore's *AI Governance Framework* ([PDPC, 2019](https://www.pdpc.gov.sg/-/media/Files/PDPC/PDF-Files/Resource-for-Organisation/AI/A-Proposed-Model-AI-Governance-Framework-January-2019.pdf)).

These documents establish the foundations for future legislative actions. However, they are often verbose and frequently lack illustrative examples. Policymakers may be used to the nature of such formal texts, but they remain unrelatable for many AI practitioners and general consumers. Yet, given the pervasive nature of AI technologies, it is all the more important for both AI practitioners and general consumers to be aware of related ethical problems, rather than treat AI as a universal panacea. As such, there is a need for a layperson guide to AI and its ethical pitfalls, that translates the formal guidelines and frameworks into simple relatable terms.

**This research project will focus specifically on crafting a guide to the subset of AI ethics known as algorithmic bias, targeted at AI practitioners and in the Singapore context.** If time allows, a second guide will target general consumers of AI technologies, who are assumed to be unfamiliar with AI. Possible future work may extend the guide to other ethical problems in AI technologies, such as privacy, explainability, accountability and news fabrication.

<div class="return-to-top"><a href="#title">[Return to top]</a></div>

---

## Research Angle - Case Studies

In this research project, I will analyze multiple case studies of:

1. AI technologies that have demonstrated algorithmic bias, 
2. Attempted solutions for these problems, and
3. Formal policies (international, national, commercial) related to algorithmic bias.

These case studies are meant to help craft the guide by:

- Collecting illustrative examples of algorithmic bias
- Discussing lessons learned from problems and attempted solutions
- Collecting best practices and tools
- Comparing Singapore's frameworks to that of other nations and organizations

<div class="return-to-top"><a href="#title">[Return to top]</a></div>

---

## Research Design

<div class="return-to-top"><a href="#title">[Return to top]</a></div>

---

## Potential Challenges

#### Catching up and Staying Up-to-date

AI ethics is the topic of the moment, with legislative bills, formal frameworks and ethics boards being announced every other day, as well as intermittent disclosures of yet another company misusing AI or data and frequent announcements of new breakthroughs by AI researchers. This poses a challenge for any researcher interested in characterizing the phenomenon, due to the flood of news everyday.

*Mitigation -* I will be making use of my collection of AI-related newsletters, that I have curated in my course as an AI researcher, to highlight pertinent AI-related stories across different fields. I will also be constraining my focus to a select number of cases, to prevent being overwhelmed.

#### Subjectivity of Ethical Concepts

The concept of ethics is notoriously debatable, with opinions ranging from the nihilistic to the extremely conservative. In my focus on algorithmic bias, I see the main conundrum as the differing definitions of *bias*, especially in the recent era of fake news, political correctness and *social justice warriors*.

*Mitigation -* I will be relying primarily on the formal definitions stated in reports by official bodies such as the UN, the European Commission, the OECD or national governments. I will attempt to integrate the multiple definitions from these sources and identify common ground to build from.

#### Keeping Things Relatable

Part of the problem of AI ethics stems from the complexity of the technology and its resulting issues. The technical nature of the technology discourages the layperson from understanding further. Furthermore, AI practitioners themselves are often more comfortable with formulas and codes and less adept at the social ramifications of their work. This is a problem of communication and of transcending boundaries.

*Mitigation -* This challenge is also the main motivation of my work - I seek to make the social problems known and relatable to AI practitioners. I will be working from my prior experience as an AI researcher and my experience from the MUSPP program. I will also be seeking feedback from friends from multiple disciplines.

<div class="return-to-top"><a href="#title">[Return to top]</a></div>

---

## Timeline

#### Weeks 1 to 2 - Groundwork

- Literature review
	- AI ethics
	- Technology adoption
	- Technology design
	- Explainers, playbooks and primers
- Scoping out deliverables
	- Outline contents for guides
	- How do we want the target audience to use the materials?
	- What specific lessons do we want them to take away?
- ~~**29 May** - Research project description~~

#### Weeks 3 to 7 - Part I

- Iterate guide_1 for practitioners
- **10 June** - IRP proposal (3-4 pages double-spaced)
- **12/19 June** - Class presentation (10min max)
- **28 June** - Complete draft guide-1 by Week 6
- Review guide_1 with target audience
- **5 July** - Literature review (for peer review)

#### Weeks 8 to 12 - Part II

- Iterate guide_2 for public
- **12 July** - Summary of findings (for peer review)
- **19 July** - Summary of contributions (for peer review)
- **26 July** - Report introduction (for peer review)
- **2 August** - Complete draft guide-2 by Week 11
- **2/9 August** - Report conclusion (for peer review)
- Review guide_2 with target audience

#### Weeks 13 to 14 Buffer

- **14 August** - Class presentation
- **18 August** - Final submission

<div class="return-to-top"><a href="#title">[Return to top]</a></div>

---

## TL;DR

In short, AI technologies are complicated and cause complicated problems that are not obvious. This project is an attempt at demystifying one of these complicated problems - algorithmic bias.

<div class="return-to-top"><a href="#title">[Return to top]</a></div>

---

## Appendix - List of Possible Case Studies

#### Case Studies of Algorithmic Bias and Proposed Solutions

- *Weapons of Math Destruction* (O'Neil, 2016)
- *Artificial Unintelligence* (Broussard, 2018)
- *Automating Inequality* (Eubanks, 2018)
- Possible examples
	- Recidivism prediction
	- Facial recognition
	- Disease prediction
	- Credit scoring

#### Case Studies of Frameworks

**International**

- European Commission's *Ethics Guidelines for Trustworthy AI* ([2019](https://ec.europa.eu/digital-single-market/en/news/ethics-guidelines-trustworthy-ai))
- OECD's *Recommendation of the Council on Artificial Intelligence* ([2019](https://legalinstruments.oecd.org/en/instruments/OECD-LEGAL-0449))
- WEF's *AI Governance: A Holistic Approach to Implement Ethics into AI* ([2019](https://www.weforum.org/whitepapers/ai-governance-a-holistic-approach-to-implement-ethics-into-ai))
- UNU's *The New Geopolitics of Converging Risks* ([2019](https://cpr.unu.edu/the-new-geopolitics-of-converging-risks-the-un-and-prevention-in-the-era-of-ai.html))
- ICDPPC's Declaration on Ethics and Data Protection in Artificial Intelligence ([2018](https://icdppc.org/public-consultation-ethics-and-data-protection-in-artificial-intelligence-continuing-the-debate/))
- EU's *Report with recommendations to the Commission on Civil Law Rules on Robotics* ([2016](http://www.europarl.europa.eu/doceo/document/A-8-2017-0005_EN.pdf))

**National**

- Canada's *Algorithmic Impact Assessment questionnaire* ([2019](https://canada-ca.github.io/aia-eia-js/))
- USA's *Algorithmic Accountability Act of 2019* ([2019](https://www.wyden.senate.gov/imo/media/doc/Algorithmic%20Accountability%20Act%20of%202019%20Bill%20Text.pdf))
- USA's *Preparing for the Future of Artificial Intelligence* ([2016](https://obamawhitehouse.archives.gov/sites/default/files/whitehouse_files/microsites/ostp/NSTC/preparing_for_the_future_of_ai.pdf))
- UK's *Ready, Willing and Able? - Select Committee on Artificial Intelligence Report 2017-19* ([2018](https://publications.parliament.uk/pa/ld201719/ldselect/ldai/100/100.pdf))
- UK's House of Commons report on robotics and artificial intelligence ([2016](https://publications.parliament.uk/pa/cm201617/cmselect/cmsctech/145/145.pdf))
- France's AI for Humanity ([2018](https://www.aiforhumanity.fr/en/))
- France's CNIL Report ([2017](https://www.cnil.fr/sites/default/files/atoms/files/cnil_rapport_ai_gb_web.pdf))
- Australia's AI Ethics Framework ([2019](https://consult.industry.gov.au/strategic-policy/artificial-intelligence-ethics-framework/))
- Beijing AI Principles (人工智能北京共识) ([2019](https://www.baai.ac.cn/blog/beijing-ai-principles))
- Singapore's *AI Governance Framework* ([PDPC, 2019](https://www.pdpc.gov.sg/-/media/Files/PDPC/PDF-Files/Resource-for-Organisation/AI/A-Proposed-Model-AI-Governance-Framework-January-2019.pdf))

**Commercial**

- Google's [principles on AI](https://www.blog.google/technology/ai/ai-principles/)
- Microsoft's [AI Principles](https://www.microsoft.com/en-us/ai/our-approach-to-ai)
- Tencent's [ARCC](https://mp.weixin.qq.com/s/_CbBsrjrTbRkKjUNdmhuqQ)
- Sony's [AI Ethics Guidelines](https://www.sony.net/SonyInfo/csr_report/humanrights/hkrfmg0000007rtj-att/AI_Engagement_within_Sony_Group.pdf)

**Non-governmental Non-commercial**

- [Montréal Declaration for a Responsible Development of Artificial Intelligence](https://www.montrealdeclaration-responsibleai.com/)
- FLI's [Asilomar AI Principles](https://futureoflife.org/ai-principles/)
- ERLC's [Artificial Intelligence: An Evangelical Statement of Principles](https://erlc.com/resource-library/statements/artificial-intelligence-an-evangelical-statement-of-principles)
- [Berkman Klein Center's report on Artificial Intelligence & Human Rights](https://cyber.harvard.edu/publication/2018/artificial-intelligence-human-rights)
- [AccessNow's Human Rights in the Age of Artificial Intelligence](https://www.accessnow.org/cms/assets/uploads/2018/11/AI-and-Human-Rights.pdf)
- [AINow 2017 Report](https://ainowinstitute.org/AI_Now_2017_Report.pdf)
- [AINow 2018 Report](https://ainowinstitute.org/AI_Now_2018_Report.pdf)
- [IEEE Ethically Aligned Design](https://ethicsinaction.ieee.org)
- [SIIA's Ethical Principles for Artificial Intelligence and Data Analytics](https://www.siia.net/Portals/0/pdf/Policy/Ethical%20Principles%20for%20Artificial%20Intelligence%20and%20Data%20Analytics%20SIIA%20Issue%20Brief.pdf?ver=2017-11-06-160346-990)
- [FATML's Principles for Accountable Algorithms and a Social Impact Statement for Algorithms](https://www.fatml.org/resources/principles-for-accountable-algorithms)

<div class="return-to-top"><a href="#title">[Return to top]</a></div>
