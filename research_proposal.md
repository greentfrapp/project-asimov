---
layout: general
title: research proposal. \| Project Asimov
permalink: /research_proposal/
---

<h1 id="title">Research Proposal</h1>

## An outline of [Project Asimov](https://greentfrapp.github.io/project-asimov/), including a brief review of existing literature, methodology, potential challenges and timeline.

<img src="https://greentfrapp.github.io/project-asimov/assets/frontispiece.png" style="width: 100%; max-width: 500px; margin: 25px;">

<dt-byline></dt-byline>

#### Contents

- [Research Background](#research-background)
- [Research Angle](#research-angle)
- [Research Design](#research-design)
- [Potential Challenges](#potential-challenges)
- [Timeline](#timeline)

---

## Research Background

Several artificial intelligence (AI) ethics guidelines and frameworks have been published recently, amidst concerns over abuse of the technology and neglect of potentially adverse consequences. Examples include the European Commission's *Ethics Guidelines for Trustworthy AI* ([2019](https://ec.europa.eu/digital-single-market/en/news/ethics-guidelines-trustworthy-ai)), the Organisation for Economic Co-operation and Development's (OECD) *Recommendation of the Council on Artificial Intelligence* ([2019](https://legalinstruments.oecd.org/en/instruments/OECD-LEGAL-0449)), Canada's *Algorithmic Impact Assessment questionnaire* ([2019](https://canada-ca.github.io/aia-eia-js/)), USA's *Algorithmic Accountability Act of 2019* ([2019](https://www.wyden.senate.gov/imo/media/doc/Algorithmic%20Accountability%20Act%20of%202019%20Bill%20Text.pdf)) and Singapore's *AI Governance Framework* ([PDPC, 2019](https://www.pdpc.gov.sg/-/media/Files/PDPC/PDF-Files/Resource-for-Organisation/AI/A-Proposed-Model-AI-Governance-Framework-January-2019.pdf)).

These documents establish the foundations for future legislative actions. However, they are often verbose and frequently lack illustrative examples. Policymakers may be used to the nature of such formal texts, but they remain unrelatable for many AI practitioners and general consumers. Yet, given the pervasive nature of AI technologies, it is all the more important for both AI practitioners and general consumers to be aware of related ethical problems, rather than treat AI as a universal panacea. As such, there is a need for a layperson guide to AI and its ethical pitfalls, that translates the formal guidelines and frameworks into simple relatable terms.

**This research project will focus specifically on crafting a guide to the subset of AI ethics known as algorithmic bias, targeted at AI practitioners and in the Singapore context.** If time allows, a second guide will target general consumers of AI technologies, who are assumed to be unfamiliar with AI. Possible future work may extend the guide to other ethical problems in AI technologies, such as privacy, explainability, accountability and news fabrication.

<div class="return-to-top"><a href="#title">[Return to top]</a></div>

---

## Research Angle - Case Studies

In this research project, I will analyze multiple case studies of:

1. AI technologies that have demonstrated algorithmic bias, 
2. Attempted solutions for these problems, and
3. Formal policies (international, national, commercial) related to algorithmic bias.

These case studies are meant to help craft the guide by:

- Collecting illustrative examples of algorithmic bias
- Discussing lessons learned from problems and attempted solutions
- Collecting best practices and tools
- Comparing Singapore's frameworks to that of other nations and organizations

<div class="return-to-top"><a href="#title">[Return to top]</a></div>

---

## Research Design

#### Case Studies of Algorithmic Bias and Proposed Solutions

- *Weapons of Math Destruction* (O'Neil, 2016)
- *Artificial Unintelligence* (Broussard, 2018)
- *Automating Inequality* (Eubanks, 2018)
- Possible examples
	- Recidivism prediction
	- Facial recognition
	- Disease prediction
	- Credit scoring

#### Case Studies of Frameworks

**International**

- European Commission's *Ethics Guidelines for Trustworthy AI* ([2019](https://ec.europa.eu/digital-single-market/en/news/ethics-guidelines-trustworthy-ai))
- OECD's *Recommendation of the Council on Artificial Intelligence* ([2019](https://legalinstruments.oecd.org/en/instruments/OECD-LEGAL-0449))
- WEF's *AI Governance: A Holistic Approach to Implement Ethics into AI* ([2019](https://www.weforum.org/whitepapers/ai-governance-a-holistic-approach-to-implement-ethics-into-ai))

**National**

- Canada's *Algorithmic Impact Assessment questionnaire* ([2019](https://canada-ca.github.io/aia-eia-js/))
- USA's *Algorithmic Accountability Act of 2019* ([2019](https://www.wyden.senate.gov/imo/media/doc/Algorithmic%20Accountability%20Act%20of%202019%20Bill%20Text.pdf))
- UK's *Select Committee on Artificial Intelligence Report 2017-19* ([2018](https://publications.parliament.uk/pa/ld201719/ldselect/ldai/100/100.pdf))
- Beijing AI Principles (人工智能北京共识) ([2019](https://www.baai.ac.cn/blog/beijing-ai-principles))
- Singapore's *AI Governance Framework* ([PDPC, 2019](https://www.pdpc.gov.sg/-/media/Files/PDPC/PDF-Files/Resource-for-Organisation/AI/A-Proposed-Model-AI-Governance-Framework-January-2019.pdf))

**Commercial**

- Google's [principles on AI](https://www.blog.google/technology/ai/ai-principles/)
- Microsoft's [AI Principles](https://www.microsoft.com/en-us/ai/our-approach-to-ai)
- Tencent's [ARCC](https://mp.weixin.qq.com/s/_CbBsrjrTbRkKjUNdmhuqQ)
- Sony's [AI Ethics Guidelines](https://www.sony.net/SonyInfo/csr_report/humanrights/hkrfmg0000007rtj-att/AI_Engagement_within_Sony_Group.pdf)

**Non-state Non-commercial**

- [Montréal Declaration for a Responsible Development of Artificial Intelligence](https://www.montrealdeclaration-responsibleai.com/)
- FHI and Oxford University's [Standards for AI Governance](https://www.fhi.ox.ac.uk/standards-technical-report/)
- ERLC's [Artificial Intelligence: An Evangelical Statement of Principles](https://erlc.com/resource-library/statements/artificial-intelligence-an-evangelical-statement-of-principles)


<div class="return-to-top"><a href="#title">[Return to top]</a></div>

---

## Potential Challenges

#### Catching up and Staying Up-to-date

#### Subjectivity of Ethical Concepts

#### Keeping Things Relatable

<div class="return-to-top"><a href="#title">[Return to top]</a></div>

---

## Timeline

#### Weeks 1 to 2 - Groundwork

- Literature review
	- AI ethics
	- Technology adoption
	- Technology design
	- Explainers, playbooks and primers
- Scoping out deliverables
	- Outline contents for guides
	- How do we want the target audience to use the materials?
	- What specific lessons do we want them to take away?
- ~~**29 May** - Research project description~~

#### Weeks 3 to 7 - Part I

- Iterate guide_1 for practitioners
- **10 June** - IRP proposal (3-4 pages double-spaced)
- **12/19 June** - Class presentation (10min max)
- **28 June** - Complete draft guide-1 by Week 6
- Review guide_1 with target audience
- **5 July** - Literature review (for peer review)

#### Weeks 8 to 12 - Part II

- Iterate guide_2 for public
- **12 July** - Summary of findings (for peer review)
- **19 July** - Summary of contributions (for peer review)
- **26 July** - Report introduction (for peer review)
- **2 August** - Complete draft guide-2 by Week 11
- **2/9 August** - Report conclusion (for peer review)
- Review guide_2 with target audience

#### Weeks 13 to 14 Buffer

- **14 August** - Class presentation
- **18 August** - Final submission

<div class="return-to-top"><a href="#title">[Return to top]</a></div>
