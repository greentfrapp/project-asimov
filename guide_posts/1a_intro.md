# Introduction to AI Ethics

*Here I give a short summary of what this website is about.*

Often, when we first fall in love, the person of our affection seems to be perfect. But the happy honeymoon is cut short when we realize they are not *that* perfect. Turns out, they've got annoying habits. They wake up with bad breath. They burp. And oh my god their farts smell just as bad as ours.

In the same way, our honeymoon with artificial intelligence (AI) is quickly giving way to a realization that AI is not perfect. Turns out, AI is not neutral. It is not necessarily right or fair. The decisions of AI systems can be just as sexist or racist as any human.

There are so many ways that AI can go wrong. There are so many guidelines from governments, companies, non-governmental organizations (NGOs). There are so many new algorithms, datasets and papers on ethical AI. It can all be a bit hard to take in, so this guide is here to help.

At the moment, the guide is targeted at AI practitioners and assumes some understanding of AI technologies. This mainly includes researchers and engineers. But it may also be useful for anyone helping to implement or recommend AI solutions.

The current version of the guide focuses on algorithmic bias. Future work will include other AI-related problems such as black boxes, privacy violations, ghost work, system failure and misinformation.

Here are some questions this guide tries to answer at different stages of the AI system lifecycle.

## Speaking to the Client

- What are the different ways to define fairness?
- How do we decide which definition to follow?
- When is AI **not** the answer?

## Collecting Data

- How do we know if our dataset is biased?
- How do we minimize bias in our dataset?
- What are some open-source datasets that are diverse?

## Training

- How do we detect and reduce bias in the training process?
- How do we control the trade-off between bias and performance?

## Deployment and Maintenance

- What should our client and users know?
- How do we consistently evaluate our models for bias?
