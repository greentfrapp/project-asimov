---
layout: default
title: 3-minute Thesis \| Machines Gone Wrong
permalink: /3mt/
---

# 3-minute Thesis

With artificial intelligence permeating into military, law enforcement, financial, healthcare, education and transport applications, what was once the fancy of science fiction authors has been made real enough to both save and endanger livelihoods and lives. In light of what is at stake, there is a growing need and a moral imperative for AI researchers, engineers and practitioners to understand the ethical issues associated with the technology.

Traditionally, analysis and evaluation of AI systems had focused on quantitative measures of accuracy and efficiency. AI practitioners are well-equipped to evaluate these metrics. But with the growing impact of AI systems on modern society, we need to look beynod these quantitative measures and start looking at the social and political impacts of these sytems. My project creates an online primer that serves to introduce AI practitioners to algorithmic bias, one out of the many aspects of these social and political impacts.

As an educational resource to algorithmic bias, my online primer serves as an alternative to academic publications and published books. In contrast to academic publications, the primer is focused on being a straightforward and relatable introduction to algorithmic bias. As opposed to published books, the primer is interactive, easily updated and freely accessible.

The primer uses real-world examples to illustrate concepts, such as the case study of COMPAS scores, used by the courts in the US to predict the probability of a criminal re-offending. Other examples include algorithmic systems used by Google, Amazon and use of facial recognition by airline carriers.

In the primer, readers can play with interactive explanations. A toy example allows readers to adjust a classifier's accuracy to fulfill different fairness definitions. Embedded Google Search iframes allow readers to see for themselves the biases that exist in Google Image Search. There are little icons scattered around the guide that can be clicked to reveal extra information for interested readers.

As a guide to AI ethics, the primer is also designed to be accessible. The primer observes the standards established by the Web Content Accessibility Guidelines (WCAG) in terms of contrast between texts and backgrounds. Colors used in diagrams were also designed to be sufficiently distinct for different groups of color-blind readers.

Finally, the primer has received favorable reviews from AI practitioners. Several of them have commented that it was a relatable and easy introduction to the topic. One reader posted a long Twitter thread asking for his followers to pay more attention to algorithmic bias and to start by reading the primer. The favorable comments suggest that there is indeed a need for this type of material that introduces AI ethics in a relatable manner. For future work, I would like to extend the primer to other topics including black boxes, privacy violations, ghost work and misinformation.
