## Introduction

With artificial intelligence (AI) permeating into military <dt-cite cite="feldman_2019,hartig_vanhoose_2019,russian_federation_2017"></dt-cite>, law enforcement <dt-cite cite="vincent_2018,angwin_larson_kirchner_mattu_2019,garvie_bedoya_frankle_2016"></dt-cite>, financial <dt-cite cite="hart_2018,patel_2018"></dt-cite>, healthcare <dt-cite cite="mullin_2018,simonite_2019a,simonite_2019b"></dt-cite> and transport <dt-cite cite="ng_2018,union_of_concerned_scientists_2017"></dt-cite> applications, what was once the fancy of science fiction authors has been made real enough to both save and endanger livelihoods and lives. In light of what is at stake, there is a growing need and a moral imperative for AI researchers, engineers and practitioners to understand the ethical issues associated with the technology.

This project aims to illustrate these issues through real-world case studies <dt-cite cite="griffiths_2016,alcine_2015,doshi_2018"></dt-cite> for practitioners implementing AI solutions. Specifically, the project will focus on the issue of **algorithmic bias** <dt-cite cite="simonite_2018,schwartz_2019"></dt-cite>. This culminates in an online guide that communicates the topic in a relatable manner and employs real-world examples.
