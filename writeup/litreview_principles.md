### Ethical Guidelines and Principles

In the context of this project, AI ethics principles refer to official publications of ethical guidelines. Such guidelines are typically published by key organizations, which can be divided into five main categories <dt-cite cite="fjeld2019principled"></dt-cite>:

- Civil society (e.g. Amnesty International, Access Now)
- Government (e.g. USA, China, Japan, Singapore)
- Multistakeholder (e.g. University of Montréal, Future of Life Institute)
- Inter-governmental organizations (e.g. Council of Europe, Organisation for Economic Co-operation and Development (OECD), United Nations (UN))
- Private sector (e.g. Google, Microsoft, Tencent)

Examples of AI ethics principles include the Amnesty International and Access Now’s Toronto Declaration (Amnesty International, 2018), USA’s Preparing for the Future of Artificial Intelligence (NSTC, 2016), University of Montréal’s Montréal Declaration, OECD’s Recommendation of the Council on Artificial Intelligence (OECD, 2019), and Microsoft’s Microsoft AI Principles (Microsoft, 2018). More recently, the Berkman Klein Center for Internet and Society at Harvard University launched the “Principled Artificial Intelligence Project” (Fjeld et al., 2019), which maps 32 sets of principles across eight themes of Privacy, Accountability, Safety and Security, Transparency and Explainability, Fairness and Non-discrimination, Human Control of Technology, Professional Responsibility, and Promotion of Human Values.