## Literature Review

<!--
- Structural Biases
- Systematic Oversight
 -->

### Structural Biases in Computer Science

The prevalance of bias in algorithmic systems can partly be traced back to the structural biases within the computer science field. Such biases comprise of gender and racial imbalances, as well as differential treatment along gender and racial lines. These biases create environments and workspaces that are not conducive for the design of inclusive systems and solutions.

Structural biases in computer science have been well-documented along gender and racial lines <dt-cite cite="catsambis1994path,tang1997glass,ong2011inside,sax2017anatomy,sosnowski2002women"></dt-cite>. In a statistical analysis of North American institutions, women make up just 15% of tenure-tracked computer science faculty <dt-cite cite="clauset2015systematic"></dt-cite>. Way et al. suggested that this gender bias might not be a result of explicit discrimination based on gender <dt-cite cite="way2016gender"></dt-cite>. Instead, Way et al. explained that "the effects of gender are indirectly incorporated into hiring decisions through gender's covariates".

In the US in 2015, "girls represented only 22 percent and underrepresented minorities only 13 percent of the approximately 50,000 students who took the Advanced Placement Computer Science (AP-CS) exam nationally" <dt-cite cite="munoz2015as"></dt-cite>. In response, the Obama Administration initiated the Computer Science for All initiative seeking for "more inclusive and accessible [Computer Science (CS)] curriculum" <dt-cite cite="smith2016computer"></dt-cite>. In a 2016 report, Singapore's Info-communications Media Development Authority (IMDA) documented the gender imbalance in the infocommunications (infocomm) industry, with only 30% of infocomm professionals being female <dt-cite cite="imda2017annual"></dt-cite>. A 2014 report by code-sharing website CodeForge showed similar gender imbalance amongst Chinese software professionals, with 20% of Chinese programmers being female <dt-cite cite="codeforge2014"></dt-cite>. Code-sharing website GitHub is popular in the international coding community and has over 5 million developers across 10 million project repositories <dt-cite cite="gousios2014lean"></dt-cite>.

In a work by Terrell et al. analyzing bias in open-source programming, gender bias is manifested in two main ways on GitHub <dt-cite cite="terrell2017gender"></dt-cite>. First, the authors only managed to identify approximately 21,000 female users, compared to approximately 310,000 male users. While the authors' target group was non-exhaustive, this reflects a gender imbalance amongst GitHub's users. Second, the authors found that contributions from female users tend to be accepted more frequently than male users when the female's gender is non-identifiable. In contrast, when a female user's gender is identifiable, they are rejected more often.

All of these form part of a larger trend of a systematic bias against certain groups in the computer science field. In turn, such biases have the potential to be embedded in the solutions and products designed by computer science professionals. Without a diverse environment, designers and engineers are more likely to be subject to echo chambers and neglect the needs of the underrepresented. Such environments are also likely to cultivate behavior that harms members of the underrepresented groups. Kabat-Farr and Cortina showed how male-dominated workspaces often record higher incidence of female harrassment and discrimination <dt-cite cite="kabat2014sex"></dt-cite>.

### Structural Biases in the Tech Industry

Beyond the racial and gender biases that plague the computer science field, other structural biases also exist in the technology industry that designs and commercializes algorithmic products. In particular, monetary incentives play a naturally outsized role in the technology industry. More often than not, these monetary incentives can be at odds with the ideals of fairness and altruism.

A Bloomberg article in 2016 reported on apparent racial disparities in the availability of Amazon's Prime Free Same-day Delivery service <dt-cite cite="ingold2016amazon"></dt-cite>. The article writes: "Amazon says its plan is to focus its same-day service on ZIP codes where there's a high concentration of Prime members, and then expand the offering to fill in the gaps over time." This might make sense from a business point of view. However, this neglects potential correlations between density of Prime members and density of different ethnic groups in the district. This decision effectively resulted in the service being denied from districts with higher proportion of black residents. By focusing exclusively on monetary goals, ethical ideals such as fairness might be sacrificed, whether intentionally or not.

A more classic example is that of redlining

### Moral Oversight in Engineering Pedagogy