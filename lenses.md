# Lenses

## Ways to approach algorithmic bias

Friedman and Nissenbaum's seminal work "Bias in Computer Systems" classifies bias as preexisting, technical and emergent.

Cramer, Garcia-Gathright, Spring and Reddy's more recent work "Assessing and Addressing Algorithmic Bias in Practice" suggests three main entry points for biases - data, algorithm and team, and desired outcomes. The advantage of this approach is that practitioners can look out for biases in a more structured manner. However, the category of "desired outcomes" feels ambiguous. The overall approach also seems overly simplistic. For instance, data bias actually comes in many forms, such as incomplete data, biased data, wrong data, poor separation of training/test etc. These have different consequences and work by different mechanisms. I wonder if there is a better way than simply grouping these under the data umbrella.

Other literature include Olteanu et al.'s "Social Data: Biases, Methdological Pitfalls, and Ethical Boundaries" and Baeza-Yates's "Data and algorithmic bias in the web". See also Narayanan's "21 Fairness Definitions and their Politics".

Key to any lens/framework would be to provide practitioners with a clear set of guidelines to detect bias.

Propp, in his treatment of the tale "Morphology of the Folktale", also suggests several other important characteristics of frameworks and classifications - indivisibility of a basic atomic unit, irreplaceability of units and clearly defined boundaries for each unit (ie. no overlaps).
