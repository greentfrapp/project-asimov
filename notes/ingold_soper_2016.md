# Amazon Doesn't Consider the Race of Its Customers. Should It?

[Link to article](https://www.bloomberg.com/graphics/2016-amazon-same-day/)

This is an excellent article on the unintended discriminatory effects of algorithms. Amazon started out offering "the promise of an egalitarian shopping experience", enabled by the anonymity of online shopping.

However, its Prime Free Same-Day Delivery service was only offered to certain districts. Notably, the service appeared to exclude poorer and blacker areas, such as the Bronx in New York City and Roxbury in Boston.

> In Atlanta, Chicago, Dallas, and Washington, cities still struggling to overcome generations of racial segregation and economic inequality, black citizens are about half as likely to live in neighborhoods with access to Amazon same-day delivery as white residents.

The article offers compelling visualizations to demonstrate the extent of the exclusion correlating to racial demographics.

But I am inclined to believe Amazon's claim that race was not a factor in their algorithms for determining which areas receive Same-Day Delivery. Instead, it is likely that the factors used in the algorithm correlate strongly with racial demographics. This then raises several important questions:

- How could Amazon have foreseen this problem?
- Should Amazon include race in its algorithms to proactively mitigate discrimination?
- What constitutes discrimination? e.g. what if we found that Amazon only offers Same-Day Delivery to places that have lower temperatures? Why is that not discriminatory?
- Is intent an important factor in discrimination?

> "As soon as you try to represent something as complex as a neighborhood with a spreadsheet based on a few variables, you've made some generalizations and assumptions that may not be true, and they may not affect all people equally," says Sorelle Friedler, a computer science professor at Haverford College who studies data bias. "There is so much systemic bias with respect to race. If you aren't purposefully trying to identify it and correct it, this bias is likely to creep into your outcomes."

> Juan Gilbert, chair of the University of Florida's department of computer and information science & engineering, says Amazon has an opportunity to use its data resources to correct its oversight and avert falling into the retail patterns of the past. "I think it was a mistake, and it never crossed their mind," he says. "This is a perfect example of how Amazon had a blind spot."
