# The Ethics of Artificial Intelligence

[Link to article](https://intelligence.org/files/EthicsofAI.pdf)

*This is part of a larger work titled Cambridge Handbook of Artificial Intelligence. Here I will only focus on Section 1, which discusses short-term issues of AI.*

> Some challenges of machine ethics are much like many other challenges involved in designing machines. Designing a robot arm to avoid crushing stray humans is no more morally fraught than designing a flame-retardant sofa.  It involves new programming challenges, but no new ethical challenges. **But when AI algorithms take on cognitive work with social dimensions — cognitive tasks previously performed by humans — the AI algorithm inherits the social requirements.** [emphasis mine]

This short two-page excerpt gives a good overview of some pertinent issues related to AI in the near future. Namely:

**Transparency**

The algorithm should allow humans (decision makers and recipients) to understand - in human terms - why a particular decision was made.

**Predictability**

The algorithm should be predictable by the humans that they govern.

> The job of the legal system is not necessarily to optimize society,but to provide a predictable environment within which citizens can optimize their own lives.

**Robustness**

The algorithm should not be susceptible to any manipulation that compromises the integrity of its decision. Consider for instance adversarial examples for image classifiers. Bostrom and Yudkowsky raise a good example of a gun detector that fails if the gun was placed next to a specific object.

**Accountability**

The algorithm should hold an entity accountable to poor decisions. The authors mention an example of an AI system with a user override. A human might be disinclined to make use of the override - if the override goes wrong, the human is responsible, whereas if the original decision was wrong, the AI is responsible.
