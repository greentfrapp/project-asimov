# Outline

**The questions at the end of the homepage should all link to a particular section in the guide.**

## Intro

- Sets the stage for AI ethics and specifically algorithmic bias.
- Sets the tone with language and images.
- Creates a hook for readers.
- Defines clear objectives.

### Images

1. [comic] At paragraph 1 - "My god" at the farts and burps
2. [comic] At paragraph 2 - "My god" at AI suggestions (parallel to 1)

## Definitions

- AI Systems - to refer to the entire supply chain and lifecycle
  - Comic to describe supply chain - Siri being a humongous monster hiding behind an iPhone
  - Comic to describe life cycle (this is an AI system egg; this is a baby AI; this is old man AI)
- AI Ethics - include Jack Clark and Meredith Whittaker's tweets
- Fairness
- Algorithmic Bias

## AI Ethics

- *When is AI not the answer?* (One of the most important questions)
  - It feels like the answer is "never".
- What makes AI different from other technologies?
  - Illusion of Impartiality
  - Speed and scale
  - Accessibility - Power to accessibility ratio
- The Responsibility of the Engineer (Great power great responsibility comic?)

### Secondary

- Review of ethical guidelines 

### Images

1. [comic] When is AI not the answer? - man holding a ton of smart gadgets, "Is that a trick question?"
2. Illusion
   1. Kid asking parent about math problem, parent uses Excel spreadsheet
   2. A robot doing something bad - I have no feelings therefore I must be fair.
3. Speed and Scale
4. [comic] Power to accessibility ratio - grid comparison of power to accessibility technologies - this should probably be in blobs - for example gold will extend across different capacities for harm, ranging from gold flakes to King Midas
   1. Nuclear Bomb - High power Low accessibility
   2. AI - Mid-High power Mid-High accessibility
   3. Knife - Low power High accessibility
   4. Gun - Mid power Mid-low accessibility
   5. Gold - Low power Low accessibility
5. [comic] At Responsibility of the Engineer - "I can code." Uncle Ben replying with great power...

## Fairness

- *What are the different ways to define fairness?*
  - Technical
  - Social (these should ideally be integrated)
  - Explorable
- *How do we decide which definition to follow?*
  - The importance of context in fairness
    - Short story about alien AI system? + comic
- *How do we control the trade-off between bias and performance?* (see demo)
- *What should our client and users know?*

### Images

- Comics for different definitions

1. [comic] Fat pets - "I think your cat needs to go on a diet." - "Stop fat-shaming her!" (cat is humongous, see Oatmeal comics)
2. [comic] Bias-accuracy trade-off - Two graphs overlaid - bias curve overlay on accuracy curve - small comics to parody extremes
3. [comic] What should clients know? - man with a lot of money, "Is that a trick question?"

## Bias

*Probably have to split into more sections*

- Types of Bias (presented initially in a table (3x2) before delving into details)
	- By Impact
		- Harms of Allocation
		- Harms of Representation
	- By Source
		- Dataset
			- *How do we know if our dataset is biased?*
			- *How do we minimize bias in our dataset?*
		- Algorithm
			- *How do we detect and reduce bias in the training process?*
			- *How do we control the trade-off between bias and performance?*
		- Deployment
			- *What should our client and users know?*
			- *How do we consistently evaluate our models for bias?*

### Images

- Comics on axes - types of impact and types of source

## Datasets

- *What are some open-source datasets that are diverse?*
- Gendered Spaces
- Inclusive Images
- Dollar Street

## Tools

- *How do we detect and reduce bias in the training process?*
- *How do we consistently evaluate our models for bias?*

## Readings

# Other Comic Ideas

On Explainability - 1st panel - witch hunt using needles - why does that make them a witch? I have no idea but look the crops are growing again. 2nd panel hiring using AI - why does that make them a good employee? I have no idea but look at all the money we are saving.