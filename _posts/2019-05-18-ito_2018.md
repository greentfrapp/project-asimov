---
layout: post
title: "Why Westerners Fear Robots and the Japanese Do Not"
ref: ito_2018
date: 2019-05-20 00:00:01
tags: culture
notes: True
---

# Why Westerners Fear Robots and the Japanese Do Not

[Link to article](https://www.wired.com/story/ideas-joi-ito-robot-overlords/)

This article veers towards the more long-term issue of robot rights and fears of robots taking over humans, which is not entirely relevant to the project. But Ito raises a good point on how our attitudes towards technology can be rooted in our culture, in this case Judeo-Christian versus Shinto.

In the context of algorithmic bias, explainability and privacy, what are important cultural contexts that these concepts are couched in? For example, how do we define *algorithmic bias*? Why is it that when an algorithm predicts higher recidivism rates for black Americans as compared to whites, we are inclined to treat this as bias rather than accepting the correlation?

> The Western concept of "humanity" is limited, and I think it's time to seriously question whether we have the right to exploit the environment, animals, tools, or robots simply because we're human and they are not.

> As Kate Darling, a researcher at the MIT Media Lab, notes in a [paper on extending legal rights to robots](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2044797), there is a great deal of evidence that human beings are sympathetic to and respond emotionally to social robotsâ€”even non-sentient ones.