---
layout: post
title: "A skeptic’s guide to thinking about AI"
ref: schwab_2018
date: 2019-05-31 00:00:01
tags: culture
notes: True
---

# A skeptic’s guide to thinking about AI

[Link to article](https://www.fastcompany.com/90252753/a-skeptics-guide-to-thinking-about-ai)

This article is a summary of the author's experience at the 2018 AI Now symposium. She highlights 4 main insights from the symposium.

1. **AI is not neutral** - It merely automates the biases that were used to train or design it.
2. **“AI” usually relies on a lot of low-paid human labor** - There is often a hidden low-wage labor component in many AI systems, which is, purposely or not, rendered invisible to users, much like many of the low-wage laborers that help to produce high-end consumer goods
3. **Don’t just talk about ethics–think about human rights** - Rather than using the term *ethics*, [Philip Alston](https://its.law.nyu.edu/facultyprofiles/index.cfm?fuseaction=profile.biography&personid=19742) argues that the term is too fuzzy and we should consider the specific components - inequality, bias, the impact of automation, the gig economy and **human rights** (which has often been neglected)
4. **We need to hold government and corporations accountable, too** - Instead of putting the blame on the technology, the authorities that choose to implement the technologies and the designers need to be held accountable for their inventions

> When you’re trying to help people using technology, you need to ensure, first and foremost, that your tool is going to affirm the self-determination and dignity of your users.
