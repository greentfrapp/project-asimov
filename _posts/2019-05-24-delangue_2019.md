---
layout: post
title: "Ethical analysis of the open-sourcing of a state-of-the-art conversational AI"
ref: delangue_2019
date: 2019-05-24 00:00:01
tags: gpt2 open-source text-generation
notes: True
---

# Ethical analysis of the open-sourcing of a state-of-the-art conversational AI

[Link to article](https://medium.com/huggingface/ethical-analysis-of-the-open-sourcing-of-a-state-of-the-art-conversational-ai-852113c324b2)

[OpenAI’s GPT-2: the model, the hype, and the controversy (by an OpenAI intern)](https://towardsdatascience.com/openais-gpt-2-the-model-the-hype-and-the-controversy-1109f4bfd5e8)

> **This is the most important takeaway: the machine learning community really, really needs to start talking openly about our standards for ethical research release.**

[Do no evil: why we need a public conversation about AI ethics](https://towardsdatascience.com/do-no-evil-why-we-need-a-public-conversation-about-ai-ethics-17366fb0f148)

> So it’s more important than ever that the general public be as engaged as possible in the debates surrounding models like GPT-2, and in broader conversations about the increasingly defining role that AI will come to play in our lives. The absence of these discussions from the political arena, and the comparative ignorance of our political class to the technical nuances of AI, are maintained at our great risk.

[Original OpenAI blog post on GPT-2](https://openai.com/blog/better-language-models/)

Since OpenAI's announcement of GPT-2, there have been many articles debating OpenAI's decision to withhold the model from the public. The fundamental question is, "Is it ethical for OpenAI to not release the GPT-2 model?" On one hand, the model can be easily exploited by malicious actors to generate fake news. On the other hand, OpenAI was founded on the idea of democratizing AI research and that this democracy would reduce the risks and harms of AI exploitation by a few.

This article in particular is a response by Hugging Face, a company that focuses on inventing social AI. Hugging Face managed to create a "state-of-the-art conversational AI" and they have chosen to release a weaker model, similar to OpenAI. In particular, this post discusses the ethical considerations by Hugging Face in choosing to open-source the weaker model.

> Despite our firm open stance, we also believe that technology is not neutral and specific action must be taken on a day-to-day basis for it to have a positive impact. For example, we publicly published [the values of our conversational artificial intelligence](https://medium.com/huggingface/artificial-intelligence-needs-values-here-are-ours-dc4268366d0f), almost a year ago.

Hugging Face discusses the possible malicious uses - "Drastic improvement of spam-bots" and "Mass catfishing and identity fraud" and they discuss some reasons why these uses do not pose excessive harm and some mitigations they have taken to reduce the harm.

More importantly, Hugging Face also provides tips for spotting conversational AIs, to further mitigate the harm from the release.

> Lastly, to mitigate both 1/ and 2/ we concluded that we should give users, regulators, and platforms some simple tricks that should help to recognize this new conversational AI from the conversation with a human to avoid any form of misleading.

This feels like a well-measured post. Simply withholding a model is not a comprehensive solution. As Ian Massingham from AWS says, "The one thing I would say about deep learning technology generally is that much of the technology is based on publicly available academic research, so you can't really put the genie back in the bottle." ([Link to article](https://www.bbc.com/news/technology-48339142)) Here, Hugging Face tries to supplement their release with discussions of possible harm and ways to mitigate that, which provides a good model for future releases by other organizations.
