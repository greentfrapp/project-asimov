---
layout: post
title: "France's AI for Humanity"
ref: france_2018
date: 2019-06-08 00:00:01
tags: framework national
frameworknotes: True
---

# France's AI for Humanity

([link](https://www.aiforhumanity.fr/en/))

*The report is also known as the Villani Report and alternatively titled For a Meaningful Artificial Intelligence — Towards a French and European Strategy. These notes focus on the following sections: **Introduction**, **Part 5 — What are the Ethics of AI?** and **Part 6 — For Inclusive and Diverse Artificial Intelligence**.*

## Defining AI

> Fundamentally, it refers to a programme whose ambitious objective is to understand and reproduce human cognition; creating cognitive processes comparable to those found in human beings.

Considers AI as a multi-disciplinary study.

> Therefore, we are naturally dealing with a wide scope here, both in terms of the technical procedures that can be employed and the various disciplines that can be called upon: mathematics, information technology, cognitive sciences, etc.

And acknowledges the significance of cultural works in shaping the perception and development of AI.

> Fantasies — often ethnocentric and based on underlying political ideologies — thus play a major role, albeit frequently disregarded, in the direction this discipline is evolving in.

Relates AI to the "datafication of the world".

> Thanks to complex algorithms, increased computing power and the exponential growth of human and machine-generated data [...] It is worth noting that progress in AI is taking place in a technological context marked by the datafication of the world [...]

The authors also touch on the political ramifications of AI (see page 5), which appears to be a major motivation for this report.

## A Meaningful AI

This report revolves around the concept of "a meaningful AI", which is defined across several paragraphs.

> A meaningful AI implies that we know the way forward.

> A meaningful AI is another way to say thatitis not an end in itself. Its development should take several considerations into account.

> A meaningful AI finally implies that AI should be explainable: explaining this technology to the public so as to demystify it—and the role of the media is vital from this point of view—but also explaining artificial intelligence by extending research into explicability itself.

## Part 5 — What are the Ethics of AI?

An ethical framework for developing and discussing AI, based on 5 principles

**Transparency and Auditability**

> In the first place, there needs to be greater transparency and auditability concerning autonomous systems.

**Data and Privacy Protection**

> Next, the protection of our rights and freedoms needs to be adapted to accommodate the potential for abuse involved in the use of machine learning systems.

**Accountability**

> Meanwhile, we need to ensure that organisations which deploy and utilize these systems remain legally responsible for any damages caused. [...] It is therefore vital that the ‘architects’ of our digital society — the researchers, engineers and developers who are designing and commercializing this technology — do their own fair share in this mission by acting responsibly. 

**Fairness and Diversity**

> [...] it would be prudent to create a genuinely diverse and inclusive social forum for discussion [...]

**Political Action**

> Finally, it becomes more crucial to politicize the issues linked to technology in general and AI in particular, in view of the important part it plays in our lives.

1. Opening the 'Black Box'

AI is a 'black box' in two ways - the opaque nature of deep learning and the complexity of the field.

This opacity leads to hidden bias and decisions having to be accepted at face value without interpretable justification.

*Proposed Solutions*

- Official governmental auditing of algorithms by specialized experts in AI and the respective fields
- Empowering non-governmental organizations and members of the public with the skills and tools to perform public auditing
- Funding research on explainable AI (XAI)

2. Considering Ethics from the Design Stage

Ethics is often neglected in the training of engineers and researchers. In the case of AI, ethics should be emphasized in the education of AI professionals.

> Currently, this aspect of their education is almost completely lacking in engineering school syllabuses and university IT courses, even though there is a constant increase in the volume and complexity of the ethical questions with which these future graduates will be confronted as they keep pace with the very rapid advances in AI.

The education of other fields such as law and social sciences should also take on the responsibility of ensuring ethical AI, by studying the basics of computer science and algorithms.

*Proposed Solutions*

- More multidisciplinary education - with engineers and researchers studying ethics and social science; with social scientists and lawyers studying computer science
- Design of a Discrimination Impact Assessment (DIA), similar to France's previous Privacy Impact Assessment (PIA), designed by the French Data Protection Authority, "to assist those with less experience in carrying out their [evaluation]"

3. Considering Collective Rights to Data

Many recent problems in AI ethics stem from loopholes and grey areas in the lagging legislation. For instance, legislation around data privacy focuses on the individual, whereas in actual fact, problems often affect entire demographics.

*Proposed Solutions*

> We are therefore proposing that compensation for injury sustained be included in this collective action.

4. How Do We Stay in Control?

In light of recent advances in AI applications, there are two main dangerous uses of AI technologies.

First is in law enforcement, where algorithms might be used in predictive policing, facial recognition and recividism prediction. These algorithms are deceptively fallible and not as objective as they appear. Furthermore, the ease of deployment of these solutions might lead to a future of mass surveillance.

*Proposed Solutions*

- Citizens should be informed of their rights to their data, their privacy and knowledge of how and why their data is being processed
- During the implementation of these algorithms, "responsibility can be attributed to a human being via a predetermined procedure"
- Highlight "areas where human judgement, fallible though it may be, should not be replaced by machines" and "consider taking steps to protect these immediately"

The second is in the military, where algorithms might be used for defence, or more terrifyingly, offensive capabilities i.e. lethal autonomous weapons systems (LAWS). 

*Proposed Solutions*

- There must be a clear demarcation between AI solutions that assist decisions and AI solutions that make decisions, and to place emphasis on understanding the risks of the latter
- An observatory on AI to be put in place, which monitors the progress of AI technologies, "along the lines of the observatory for the non-proliferation of nuclear, biological and chemical weapons"

5. Specific Governance of Ethics in Artificial Intelligence

*Proposed Solutions*

- A national advisory committee on ethics for digital technology and artificial intelligence
	- "This new committee must also be able to advise the State on its own technological choices: whether at national level (such as choices made by the State concerning the use of AI for surveillance, etc.) or at international level (France’s position on autonomous weapons)."
	- "the committee should be tasked with coordinating and sustaining ethical debate in society by organizing events, holding public consultations both online and off line, making tools and assistance available for the coordination of autonomous debates, carrying out surveys and opinion polls on the various issues, etc."


